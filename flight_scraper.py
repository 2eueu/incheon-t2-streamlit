# flight_scraper.py
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import Select, WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from datetime import datetime
import time
import json

def get_flight_data():
    # âœ… í¬ë¡¬ ì˜µì…˜ ì„¤ì • (headless í™˜ê²½ìš©)
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920,1080')

    # âœ… í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    url = "https://www.airport.kr/ap_ko/869/subview.do"
    driver.get(url)
    print(f"ðŸŒ ì ‘ì†í•œ URL: {url}")
    time.sleep(2)

    # âœ… ë‚ ì§œ ì„¤ì • (í•œêµ­ì–´ ìš”ì¼ í¬í•¨)
    today = datetime.now()
    weekday_map = {'Mon': 'ì›”', 'Tue': 'í™”', 'Wed': 'ìˆ˜', 'Thu': 'ëª©', 'Fri': 'ê¸ˆ', 'Sat': 'í† ', 'Sun': 'ì¼'}
    weekday_kor = weekday_map[today.strftime('%a')]
    today_str = today.strftime(f"%Y.%m.%d ({weekday_kor})")
    print(f"ðŸ“… ì˜¤ëŠ˜ ë‚ ì§œ: {today_str}")

    # âœ… ë“œë¡­ë‹¤ìš´ ì„ íƒ
    Select(driver.find_element(By.ID, "daySel")).select_by_visible_text(today_str)
    Select(driver.find_element(By.ID, "termId")).select_by_visible_text("T2")
    Select(driver.find_element(By.ID, "fromTime")).select_by_visible_text("00:00")
    Select(driver.find_element(By.ID, "toTime")).select_by_visible_text("23:59")
    time.sleep(10)

    # ðŸ” HTML ì¼ë¶€ ì¶œë ¥í•´ì„œ ë Œë”ë§ í™•ì¸!
    print("ðŸ“„ íŽ˜ì´ì§€ ì¼ë¶€ HTML:")
    print(driver.page_source[:1500])
    
    # âœ… ì•ˆì •ì ì¸ ë²„íŠ¼ í´ë¦­ (ìˆ˜ì • í¬ì¸íŠ¸!)
    wait = WebDriverWait(driver, 20)
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "button.btn-search")))
    wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "button.btn-search"))).click()
    time.sleep(3)

    # âœ… íŽ˜ì´ì§€ ìŠ¤í¬ë¡¤
    body = driver.find_element(By.TAG_NAME, "body")
    last_height = driver.execute_script("return document.body.scrollHeight")
    for _ in range(30):
        body.send_keys(Keys.END)
        time.sleep(1.5)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

    # âœ… ë°ì´í„° íŒŒì‹±
    soup = BeautifulSoup(driver.page_source, "html.parser")
    flight_blocks = soup.select("button.toggle")

    if not flight_blocks:
        print("âš ï¸ No flight data found. Check if the page loaded properly.")

    results = []
    for block in flight_blocks:
        try:
            dep_time = block.select_one("div.time > strong").text.strip()
            destination = block.select_one("div.location > em").text.strip()
            gate = block.select_one("div.enter > em").text.strip()
            results.append({
                "departure_time": dep_time,
                "destination": destination,
                "gate": gate
            })
        except:
            continue

    driver.quit()

    # âœ… JSON ì €ìž¥
    with open("data/flights.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"âœ… ì €ìž¥ ì™„ë£Œ: {len(results)} flights saved to data/flights.json")

if __name__ == "__main__":
    get_flight_data()
